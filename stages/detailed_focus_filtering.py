import shutil
import logging
from pathlib import Path
from typing import List, Any, Optional

from processing.document_parser import get_document_content, get_semantic_splitter, split_document_into_nodes
from processing.llm_interactor import llm_get_score_for_chunk
from core.prompts import get_chunk_focus_scoring_prompt

logger = logging.getLogger("DataPipeline")

def _calculate_average_chunk_focus_score(
    file_path: Path,
    topic: str,
    semantic_splitter: Any,
    llm_client: Any,
    llm_provider_name: str,
    llm_scoring_model_name: str,
    llm_temperature: float,
    llm_max_retries: int,
    llm_retry_delay: int) -> Optional[float]:
    """
    Calculates the average FOCUS score for all chunks in a given file using SemanticSplitter.
    """
    
    logger.debug(f"Calculating average chunk FOCUS score for: {file_path.name}, topic: '{topic}'")
    
    file_content = get_document_content(file_path)
    if file_content is None:
        logger.error(f"Could not read content from {file_path.name} for focus scoring.")
        return None
    
    if not file_content.strip():
        logger.warning(f"File {file_path.name} is empty or contains only whitespace. Assigning focus score 0.0.")
        return 0.0

    text_nodes = split_document_into_nodes(file_content, file_path.name, semantic_splitter)
    if not text_nodes:
        logger.warning(f"No text nodes/chunks generated by SemanticSplitter for {file_path.name}, cannot calculate average focus score.")
        return None

    scores: List[int] = []
    for i, node in enumerate(text_nodes):
        chunk_text = node.get_content()
        
        if not chunk_text.strip():
            logger.debug(f"Skipping empty chunk {i+1}/{len(text_nodes)} in {file_path.name} (Focus Scoring with SemanticSplitter).")
            continue

        score = llm_get_score_for_chunk(
            llm_client=llm_client,
            provider_name=llm_provider_name,
            model_name=llm_scoring_model_name,
            topic=topic,
            chunk_text=chunk_text,
            temperature=llm_temperature,
            max_retries=llm_max_retries,
            retry_delay=llm_retry_delay,
            scoring_prompt_func=get_chunk_focus_scoring_prompt
        )
        
        if score is not None:
            logger.debug(f"Chunk {i+1}/{len(text_nodes)} of {file_path.name} (Focus Semantic) scored: {score}")
            scores.append(score)
            
        else:
            logger.warning(f"Failed to get focus score for chunk {i+1}/{len(text_nodes)} of {file_path.name} (Focus Semantic). Chunk will be ignored.")

    if not scores:
        logger.warning(f"No chunks were successfully focus-scored for {file_path.name} (Focus Semantic). Cannot calculate average.")
        return None
    
    average_score = sum(scores) / len(scores)
    logger.info(f"File: {file_path.name} (Focus Semantic) - Scored Chunks: {len(scores)}/{len(text_nodes)} - Average FOCUS Score: {average_score:.2f}")
    
    return average_score


def run_detailed_focus_filtering(
    input_files_from_stage3: List[Path],
    output_focused_files_dir: Path,
    topic: str,
    focus_threshold: int,
    # SemanticSplitter config
    embedding_provider: str,
    ollama_embed_model: Optional[str],
    ollama_url: Optional[str],
    st_embed_model: Optional[str],
    semantic_splitter_buffer: int,
    semantic_splitter_breakpoint_perc: int,
    # LLM config
    llm_client: Any,
    llm_provider_name: str,
    llm_scoring_model_name: str,
    llm_temperature: float,
    llm_max_retries: int,
    llm_retry_delay: int ) -> List[Path]:
    """
    Executes Stage 4: Filters files from Stage 3 based on average chunk FOCUS score
    using SemanticSplitter. Copies focused files to the output directory.
    """
    
    logger.info(f"--- Starting Stage 4: Detailed File Filtering (Focus Scoring) ---")
    logger.info(f"Input files (from Stage 3): {len(input_files_from_stage3)}")
    logger.info(f"Output directory for focused files: {output_focused_files_dir.resolve()}")
    logger.info(f"Topic: '{topic}', Focus Threshold: {focus_threshold}")

    output_focused_files_dir.mkdir(parents=True, exist_ok=True)

    if not input_files_from_stage3:
        logger.warning("No files received from Stage 3. Stage 4 has no files to process.")
        return []

    try:
        semantic_splitter = get_semantic_splitter(
            embedding_model_provider=embedding_provider,
            ollama_embedding_model_name=ollama_embed_model,
            ollama_base_url=ollama_url,
            sentence_transformers_model_name=st_embed_model,
            buffer_size=semantic_splitter_buffer,
            breakpoint_percentile_threshold=semantic_splitter_breakpoint_perc
        )
        
    except Exception as e:
        logger.critical(f"Failed to initialize SemanticSplitter for Stage 4: {e}. Aborting Stage 4.", exc_info=True)
        return []


    focused_file_paths: List[Path] = []
    for file_path in input_files_from_stage3:
        logger.info(f"\nProcessing file for focus: {file_path.name}")
        
        average_focus_score = _calculate_average_chunk_focus_score(
            file_path=file_path,
            topic=topic,
            semantic_splitter=semantic_splitter,
            llm_client=llm_client,
            llm_provider_name=llm_provider_name,
            llm_scoring_model_name=llm_scoring_model_name,
            llm_temperature=llm_temperature,
            llm_max_retries=llm_max_retries,
            llm_retry_delay=llm_retry_delay
        )

        if average_focus_score is not None:
            
            if average_focus_score >= focus_threshold:
                logger.info(f"File '{file_path.name}' marked FOCUSED (Avg Focus Score: {average_focus_score:.2f} >= {focus_threshold})")
                
                destination_path = output_focused_files_dir / file_path.name
                try:
                    shutil.copy2(file_path, destination_path)
                    logger.info(f"Copied '{file_path.name}' to '{destination_path}'")
                    focused_file_paths.append(destination_path)
                
                except Exception as e:
                    logger.error(f"Failed to copy focused file {file_path.name} to {destination_path}: {e}", exc_info=True)
            
            else:
                logger.info(f"File '{file_path.name}' marked NOT FOCUSED ENOUGH (Avg Focus Score: {average_focus_score:.2f} < {focus_threshold})")
        
        else:
            logger.warning(f"Could not determine focus for {file_path.name} (average focus score calculation failed). File will be SKIPPED.")

    logger.info(f"--- Finished Stage 4: Detailed File Filtering. Copied {len(focused_file_paths)} focused files. ---")
    
    return focused_file_paths
